# Impact

- Word count: **1,000**

## Impact on general public

The launch of the CERN Open Data portal in November 2014 and the publication of
the CMS primary datasets (27 TB), derived datasets, interactive event display
tools, the CMS virtual machines and the analysis software examples was met with
a significant interest from general public.

The launch was covered by major news networks and social media, with many
articles inviting readers to run an LHC physics "in your living room". In the
month following the release, more than 80,000 people visited the portal, which
is several times more than the active particle physics community. Most of
visitors spent time in browsing around site and using provided interactive
tools. Several thousands of visitors explored the provided data to the full by
means of studying primary datasets and downloading virtual machines and software
to analyse the data.

Two weeks after the launch of the portal, an "Ask Me Anything" session was
organised on Reddit where readers could ask questions about open data and open
science practices at CERN. The Reddit AMA session attracted considerable
attention and led to another peak of the CERN Open Data Portal use.

The public interest in the released open data generated several non-physics use
case scenarios, such as using released datasets as a robust input for digital
forensics studies related to cloud computing security. It was interesting to see
possible applications outside of our primary target area.

## Impact on scientists

When the CMS collaboration first drafted the Open Access policy in 2012, the concept of open research data was totally new in High Energy Physics. Several concerns were expressed within the collaboration, mainly addressing the eventual additional workload to the collaboration members in case someone would claim contradictory or false results based on the open data. The very concept of open data was new: the researchers - correctly - see the published result as the goal of the research work, and publishing data without results may have been seen as unnecessary, premature or meaningless.

It was, however, considered that the benefits of the open data, in terms of preserving their scientific potential and enabling their use in education, widely overcome the potential risks. Indeed, the first data release in 2014 gave overwhelmingly positive feedback and the CMS collaboration has now accepted the concept of further regular data releases.

The core of the public CMS data are in the same format as used internally for data analysis. While some examples of derived data are provided on the Open Data Portal, for the core data there is no simplification or curation of these data particularly for public release. They are part of the legacy data, which are reprocessed with a single software version for a longer period of data-taking (e.g. one version for 2010 data and another version for 2011-2012). This was considered only viable solution for releasing substantial amount of scientific data, as in this case no time- and resource-consuming additional reprocessing and validation for public data is needed. Furthermore, the exact provenance details (software versions, configuration parameters) can be directly extracted from the CMS internal data description systems.

Making data public does not make them any simpler. Finding human resources to provide adequate instructions and documentation is a concern for a collaboration in active data-taking phase, with all resources focused on collecting and analysing new data. The experience of the first data release was instructive: even if the preparations for the data to be released were started with a fairly short delay after the last reprocessing of these data and considering that some of the last publications on these data were done just a bit earlier, finding the correct set of instructions and documentation was not an easy task for many simple reasons. The people in charge have moved to different positions, the documentation have been updated and finding the correct set of instructions corresponding to the exact software release is not as obvious as as it may seem. Having learnt from this, CMS is now collecting the instructions for the freshly collected data to be released in the future.

Preparing well in advance for the public data release has a major impact on the long-term data and knowledge preservation in the collaboration, and the necessity of starting it when the data are in active use is well motivated by the public data release. Furthemore, providing instructions on how to use data puts the emphasis on the most difficult area in the data preservation: the preservation of knowledge, which at the time of the active use of the data is so much part of the every day work that it may not even have been written down.
