## Impact on scientists

When the CMS Collaboration first drafted its open-data policy in 2012, the concept of open research data was entirely new in high-energy physics. The researchers -- correctly -- see the published result as the goal of the research work, and publishing data on their own was seen by some as unnecessary, premature or meaningless. Several concerns were expressed within the collaboration, mainly addressing the potential additional workload for collaboration members in case someone presents contradictory or false results based on the open data from CMS. It was, however, considered that the benefits of the open data, both in terms of preserving their scientific potential and in enabling their use in education, overcome any potential risks.

The core of the public CMS data are in the same format as used internally for data analysis. While some examples of derived data are provided on the Portal, for the core data there is no simplification or curation of these data particularly for public release. They are part of the legacy data, which are reprocessed with a single software version for a longer period of data-taking (e.g. one version for 2010 data and another version for 2011-2012). This was considered only viable solution for releasing substantial amount of scientific data, as in this case no time- and resource-consuming additional reprocessing and validation for public data is needed. Furthermore, the exact provenance details (software versions, configuration parameters) can be directly extracted from the CMS internal data description systems.

Making data public does not make them any simpler. Finding human resources to provide adequate instructions and documentation is a concern for a collaboration in active data-taking phase, with all resources focused on collecting and analysing new data. The experience of the first data release was instructive: even if the preparations for the data to be released were started with a fairly short delay after the last reprocessing of these data and considering that some of the last publications on these data were done just a bit earlier, finding the correct set of instructions and documentation was not an easy task for many simple reasons. The people in charge have moved to different positions, the documentation have been updated and finding the correct set of instructions corresponding to the exact software release is not as obvious as as it may seem. Having learnt from this, CMS is now collecting the instructions for the freshly collected data to be released in the future.

Preparing well in advance for the public data release has a major impact on the long-term data and knowledge preservation in the collaboration, and the necessity of starting it when the data are in active use is well motivated by the public data release. Furthemore, providing instructions on how to use data puts the emphasis on the most difficult area in the data preservation: the preservation of knowledge, which at the time of the active use of the data is so much part of the every day work that it may not even have been written down.

The overwhelmingly positive feedback received following the first data release in 2014 has led to the CMS Collaboration now accepting the concept of further regular data releases.
