# Impact

## Impact on general public

The launch of the CERN Open Data Portal in November 2014 along with the publication of the CMS primary datasets (27 TB), derived datasets, interactive event visualiser, the CMS virtual machines and the analysis software examples was met with considerable interest from the general public.

The launch was covered by major news networks and on social media, with many articles inviting readers to run an LHC physics analysis "in your living room". In the month following the release, more than 80,000 people visited the portal, which is several times larger than the active particle-physics community (estimated at around 20,000). Most of the visitors spent time browsing around the site and using the provided interactive tools. Several thousands of visitors explored the provided data by downloading the virtual machines and software to study the datasets.

Two weeks after the launch of the portal, an ["Ask Me Anything" session was
organised on Reddit](https://www.reddit.com/r/IAmA/comments/2nxwkb/a_few_days_ago_cern_launched_an_open_data_portal/), where readers could ask questions about open data and open-science practices at CERN. The Reddit AMA session attracted considerable
attention and led to another peak in visitors to the CERN Open Data Portal.

The public interest in the released open data generated some non-physics use
case scenarios, such as using the large datasets as a robust input for digital
forensics studies related to security in cloud computing. It is enlightening to see possible applications outside of the primary focus of the data, which is physics analysis.

## Impact on scientists

When the CMS Collaboration first drafted its open-data policy in 2012, the concept of open research data was entirely new in high-energy physics. The researchers -- correctly -- see the published result as the goal of the research work, and publishing data on their own was seen by some as unnecessary, premature or meaningless. Several concerns were expressed within the collaboration, mainly addressing the potential additional workload for collaboration members in case someone presents contradictory or false results based on the open data from CMS. It was, however, considered that the benefits of the open data, both in terms of preserving their scientific potential and in enabling their use in education, overcome any potential risks.

The core of the public CMS data are in the same format as used internally for data analysis. While some examples of derived data are provided on the Portal, for the core data there is no simplification or curation of these data particularly for public release. They are part of the legacy data, which are reprocessed with a single software version for a longer period of data-taking (e.g. one version for 2010 data and another version for 2011-2012). This was considered only viable solution for releasing substantial amount of scientific data, as in this case no time- and resource-consuming additional reprocessing and validation for public data is needed. Furthermore, the exact provenance details (software versions, configuration parameters) can be directly extracted from the CMS internal data description systems.

Making data public does not make them any simpler. Finding human resources to provide adequate instructions and documentation is a concern for a collaboration in active data-taking phase, with all resources focused on collecting and analysing new data. The experience of the first data release was instructive: even if the preparations for the data to be released were started with a fairly short delay after the last reprocessing of these data and considering that some of the last publications on these data were done just a bit earlier, finding the correct set of instructions and documentation was not an easy task for many simple reasons. The people in charge have moved to different positions, the documentation have been updated and finding the correct set of instructions corresponding to the exact software release is not as obvious as as it may seem. Having learnt from this, CMS is now collecting the instructions for the freshly collected data to be released in the future.

Preparing well in advance for the public data release has a major impact on the long-term data and knowledge preservation in the collaboration, and the necessity of starting it when the data are in active use is well motivated by the public data release. Furthemore, providing instructions on how to use data puts the emphasis on the most difficult area in the data preservation: the preservation of knowledge, which at the time of the active use of the data is so much part of the every day work that it may not even have been written down.

The overwhelmingly positive feedback received following the first data release in 2014 has led to the CMS Collaboration now accepting the concept of further regular data releases.
