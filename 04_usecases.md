# Use cases

- Themes:
    1. Education (Authors: @tpmccauley)
    2. Research (Authors: @katilp, Achim?)
- Word count: **2,000**

Primary datasets from the LHC experiments reflect the complexity of the experiments themselves. To be able to extract anything meaningful from these datasets one needs at least: knowledge of the physics involved, familiarity with the data format, knowledge of the detector and its performance, a software environment and API particular to the experiment, and software expertise. These are significant hurdles for the general public.

Derived datasets are reductions of the primary datasets in the sense that only part of the information in the primary datasets is kept and/or only some of the events in the primary datasets are selected. Very often the derived datasets are produced in ope, human-readable formats such as CSV, XML, and JSON; this is only possible when some of the information is kept from the primary datasets. 

The actual content and level of complexity of a particular derived dataset often depends on the intended audience. Open data as distributed in derived datasets find widest use in so-called masterclasses. Here, the intended audience are students at the high-school level. The purpose of the masterclass is to teach students a bit about particle physics, the experiments and detectors used to study it, and to give a sense of what it is like to analyse data and to obtain a result.

The material available as educational content in the open data portal includes: derived datasets prepared for specific educational exercises such as masterclasses and tutorials and for applications such as event displays, example analysis code, and virtual machine environment with experiment software. Also included are links to further documentation and information.
